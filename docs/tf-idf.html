<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 TDF-IDF | Research Book</title>
  <meta name="description" content="This is my daily research book for analysis and documentation" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 TDF-IDF | Research Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my daily research book for analysis and documentation" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 TDF-IDF | Research Book" />
  
  <meta name="twitter:description" content="This is my daily research book for analysis and documentation" />
  

<meta name="author" content="Shamsuddeen Muhammad" />


<meta name="date" content="2020-10-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="SA.html"/>

<script src="libs/header-attrs-2.4/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> My PhD Research Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About this Summary Book</a></li>
<li class="chapter" data-level="2" data-path="tidytext.html"><a href="tidytext.html"><i class="fa fa-check"></i><b>2</b> Tidy text format</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tidytext.html"><a href="tidytext.html#chapter-take-away"><i class="fa fa-check"></i><b>2.1</b> Chapter Take Away</a></li>
<li class="chapter" data-level="" data-path="tidytext.html"><a href="tidytext.html#contrasting-tidy-text-with-other-data-structures"><i class="fa fa-check"></i>1.1 Contrasting tidy text with other data structures</a></li>
<li class="chapter" data-level="" data-path="tidytext.html"><a href="tidytext.html#the-unnest_tokens-function"><i class="fa fa-check"></i>1.2 The unnest_tokens function</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="tidytext.html"><a href="tidytext.html#sentences"><i class="fa fa-check"></i><b>2.1.1</b> Sentences</a></li>
<li class="chapter" data-level="2.1.2" data-path="tidytext.html"><a href="tidytext.html#word"><i class="fa fa-check"></i><b>2.1.2</b> Word</a></li>
<li class="chapter" data-level="2.1.3" data-path="tidytext.html"><a href="tidytext.html#chapter"><i class="fa fa-check"></i><b>2.1.3</b> Chapter</a></li>
<li class="chapter" data-level="2.1.4" data-path="tidytext.html"><a href="tidytext.html#by-n-gram"><i class="fa fa-check"></i><b>2.1.4</b> By n-gram</a></li>
<li class="chapter" data-level="2.1.5" data-path="tidytext.html"><a href="tidytext.html#tri-gram"><i class="fa fa-check"></i><b>2.1.5</b> tri-gram</a></li>
<li class="chapter" data-level="2.1.6" data-path="tidytext.html"><a href="tidytext.html#character_-shingles-defined-character"><i class="fa fa-check"></i><b>2.1.6</b> character_ shingles : Defined character</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidytext.html"><a href="tidytext.html#tidying-the-works-of-jane-austen"><i class="fa fa-check"></i>1.3 Tidying the works of Jane Austen</a></li>
<li class="chapter" data-level="" data-path="tidytext.html"><a href="tidytext.html#the-gutenbergr-package"><i class="fa fa-check"></i>1.4 The gutenbergr package</a></li>
<li class="chapter" data-level="" data-path="tidytext.html"><a href="tidytext.html#word-frequencies"><i class="fa fa-check"></i>1.5 Word frequencies</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="SA.html"><a href="SA.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="tidytext.html"><a href="tidytext.html#chapter-take-away"><i class="fa fa-check"></i><b>3.1</b> Chapter Take Away</a></li>
<li class="chapter" data-level="3.2" data-path="SA.html"><a href="SA.html#sentiment-analysis"><i class="fa fa-check"></i><b>3.2</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#the-sentiments-dataset"><i class="fa fa-check"></i>2.1 The sentiments dataset</a></li>
<li class="chapter" data-level="3.3" data-path="SA.html"><a href="SA.html#lexicon-package-not-in-the-book"><i class="fa fa-check"></i><b>3.3</b> Lexicon package not in the book</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#sentiment-analysis-with-inner-join"><i class="fa fa-check"></i>2.2 Sentiment analysis with inner join</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#comparing-the-three-sentiment-dictionaries"><i class="fa fa-check"></i>2.3 Comparing the three sentiment dictionaries</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#most-common-positive-and-negative-words"><i class="fa fa-check"></i>2.4 Most common positive and negative words</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#wordclouds"><i class="fa fa-check"></i>2.5 Wordclouds</a></li>
<li class="chapter" data-level="" data-path="SA.html"><a href="SA.html#looking-at-units-beyond-just-words"><i class="fa fa-check"></i>2.6 Looking at units beyond just words</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tf-idf.html"><a href="tf-idf.html"><i class="fa fa-check"></i><b>4</b> TDF-IDF</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tidytext.html"><a href="tidytext.html#chapter-take-away"><i class="fa fa-check"></i><b>4.1</b> Chapter Take Away</a></li>
<li class="chapter" data-level="4.2" data-path="tf-idf.html"><a href="tf-idf.html#the-tidy-text-format"><i class="fa fa-check"></i><b>4.2</b> The tidy text format</a></li>
<li class="chapter" data-level="" data-path="tf-idf.html"><a href="tf-idf.html#term-frequency-in-jane-austens-novels"><i class="fa fa-check"></i>3.1 Term frequency in Jane Austen’s novels</a></li>
<li class="chapter" data-level="" data-path="tf-idf.html"><a href="tf-idf.html#zipfs-law"><i class="fa fa-check"></i>3.2 Zipf’s law</a></li>
<li class="chapter" data-level="" data-path="tf-idf.html"><a href="tf-idf.html#the-bind_tf_idf-function"><i class="fa fa-check"></i>3.3 The bind_tf_idf function</a></li>
<li class="chapter" data-level="" data-path="tf-idf.html"><a href="tf-idf.html#a-corpus-of-physics-texts"><i class="fa fa-check"></i>3.4 A corpus of physics texts</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.shmuhammad.com/" target="blank">Find more summary of books I read preview_chapter(</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tf-idf" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> TDF-IDF</h1>
<div id="chapter-take-away" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Chapter Take Away</h2>
<div class="note">
<p><strong>Take away</strong></p>
<ul>
<li><p>Term frequency:</p></li>
<li><p>tf</p></li>
<li><p>idf</p></li>
<li><p>td_idf: tf-idf measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites</p></li>
<li><p>Using term frequency and inverse document frequency allows us to find words that are characteristic for one document within a collection of documents, whether that document is a novel or physics text or webpage. Exploring term frequency on its own can give us insight into how language is used in a collection of natural language, and dplyr verbs like count() and rank() give us tools to reason about term frequency. The tidytext package uses an implementation of tf-idf consistent with tidy data principles that enables us to see how different words are important in documents within a collection or corpus of documents.</p></li>
</ul>
</div>
</div>
<div id="the-tidy-text-format" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> The tidy text format</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="tf-idf.html#cb1-1"></a><span class="kw">library</span>(tidytext)</span>
<span id="cb1-2"><a href="tf-idf.html#cb1-2"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="tf-idf.html#cb1-3"></a><span class="kw">library</span>(janeaustenr)</span></code></pre></div>
<p>One of the question in text mining and NLP is to find out what a document is about.</p>
<p>Can we do this by looking at the words that make up the document? One measure of how important a word may be is its <strong>term frequency (tf), which shows how frequently a word occurs in a document</strong>. But, there may be some words that appears many times but may not be important; in English, these are probably words like “the”, “is”, “of”, and so forth.</p>
<p>We might think removing stop words in analysis, but stop words sometimes have more important than other words. Removing list of stop words is not a very sophisticated approach to adjusting term frequency for commonly used words.</p>
<blockquote>
<p>The common approach is to look at a term’s inverse document frequency (idf) - which decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents.
This can be combined with term frequency to calculate a term’s tf-idf (the two quantities multiplied together), the <code>frequency of a term adjusted for how rarely it is used.</code></p>
</blockquote>
<div class="note">
<p>The statistic tf-idf is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites</p>
</div>
<p>It is a rule-of-thumb or heuristic quantity; while it has proved useful in text mining, search engines, etc., its theoretical foundations are considered less than firm by information theory experts</p>
<p><img src="images/idf.png" /></p>
<p>We can use tidy data principle, to perform <code>tf-idf</code> analysis to quantify how important various terms are in a document that is part of a collection.</p>
</div>
<div id="term-frequency-in-jane-austens-novels" class="section level2 unnumbered" number="">
<h2>3.1 Term frequency in Jane Austen’s novels</h2>
<p>Let us find term frequency and then tf-idf of Jane Austen novels.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="tf-idf.html#cb2-1"></a>book_words &lt;-<span class="st"> </span><span class="kw">austen_books</span>() <span class="op">%&gt;%</span></span>
<span id="cb2-2"><a href="tf-idf.html#cb2-2"></a><span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) <span class="op">%&gt;%</span></span>
<span id="cb2-3"><a href="tf-idf.html#cb2-3"></a><span class="st">  </span><span class="kw">count</span>(book, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</span>
<span id="cb2-4"><a href="tf-idf.html#cb2-4"></a></span>
<span id="cb2-5"><a href="tf-idf.html#cb2-5"></a>book_words</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 3
##    book              word      n
##    &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;
##  1 Mansfield Park    the    6206
##  2 Mansfield Park    to     5475
##  3 Mansfield Park    and    5438
##  4 Emma              to     5239
##  5 Emma              the    5201
##  6 Emma              and    4896
##  7 Mansfield Park    of     4778
##  8 Pride &amp; Prejudice the    4331
##  9 Emma              of     4291
## 10 Pride &amp; Prejudice to     4162
## # … with 40,369 more rows</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="tf-idf.html#cb4-1"></a>total_words &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-2"><a href="tf-idf.html#cb4-2"></a><span class="st">  </span><span class="kw">group_by</span>(book) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-3"><a href="tf-idf.html#cb4-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(n))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="tf-idf.html#cb6-1"></a>total_words</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   book                 total
##   &lt;fct&gt;                &lt;int&gt;
## 1 Sense &amp; Sensibility 119957
## 2 Pride &amp; Prejudice   122204
## 3 Mansfield Park      160460
## 4 Emma                160996
## 5 Northanger Abbey     77780
## 6 Persuasion           83658</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="tf-idf.html#cb8-1"></a>book_words &lt;-<span class="st"> </span><span class="kw">left_join</span>(book_words, total_words)</span></code></pre></div>
<pre><code>## Joining, by = &quot;book&quot;</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="tf-idf.html#cb10-1"></a>book_words</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 4
##    book              word      n  total
##    &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;  &lt;int&gt;
##  1 Mansfield Park    the    6206 160460
##  2 Mansfield Park    to     5475 160460
##  3 Mansfield Park    and    5438 160460
##  4 Emma              to     5239 160996
##  5 Emma              the    5201 160996
##  6 Emma              and    4896 160996
##  7 Mansfield Park    of     4778 160460
##  8 Pride &amp; Prejudice the    4331 122204
##  9 Emma              of     4291 160996
## 10 Pride &amp; Prejudice to     4162 122204
## # … with 40,369 more rows</code></pre>
<p>Now, for each word we have its total in the book and total number of words in the book. Look at those with highest n, they seems to be the stop words like <code>the</code>, <code>to</code>, <code>and</code>, <code>of</code>, etc.</p>
<div id="term-frequency" class="section level4" number="4.2.0.1">
<h4><span class="header-section-number">4.2.0.1</span> Term frequency</h4>
<p>let’s look at the distribution of n/total for each novel, the number of times a word appears in a novel divided by the total number of terms (words) in that novel. <code>This is exactly what term frequency is</code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="tf-idf.html#cb12-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb12-2"><a href="tf-idf.html#cb12-2"></a></span>
<span id="cb12-3"><a href="tf-idf.html#cb12-3"></a><span class="kw">ggplot</span>(book_words, <span class="kw">aes</span>(n<span class="op">/</span>total, <span class="dt">fill =</span> book)) <span class="op">+</span></span>
<span id="cb12-4"><a href="tf-idf.html#cb12-4"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb12-5"><a href="tf-idf.html#cb12-5"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="ot">NA</span>, <span class="fl">0.0009</span>) <span class="op">+</span></span>
<span id="cb12-6"><a href="tf-idf.html#cb12-6"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>book, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 896 rows containing non-finite values (stat_bin).</code></pre>
<pre><code>## Warning: Removed 6 rows containing missing values (geom_bar).</code></pre>
<p><img src="Reseach-Book_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Term frequency in the table:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="tf-idf.html#cb16-1"></a>book_words &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term_fre=</span>  n<span class="op">/</span>total)</span>
<span id="cb16-2"><a href="tf-idf.html#cb16-2"></a>book_words</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 5
##    book              word      n  total term_fre
##    &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;
##  1 Mansfield Park    the    6206 160460   0.0387
##  2 Mansfield Park    to     5475 160460   0.0341
##  3 Mansfield Park    and    5438 160460   0.0339
##  4 Emma              to     5239 160996   0.0325
##  5 Emma              the    5201 160996   0.0323
##  6 Emma              and    4896 160996   0.0304
##  7 Mansfield Park    of     4778 160460   0.0298
##  8 Pride &amp; Prejudice the    4331 122204   0.0354
##  9 Emma              of     4291 160996   0.0267
## 10 Pride &amp; Prejudice to     4162 122204   0.0341
## # … with 40,369 more rows</code></pre>
</div>
</div>
<div id="zipfs-law" class="section level2 unnumbered" number="">
<h2>3.2 Zipf’s law</h2>
<blockquote>
<p>Given a large corpus of natural language occurrences, the frequency of any word is inversely proportional to its rank in frequency table.</p>
</blockquote>
<p>The plots we obtain in the previous section agree whith Zips law.</p>
<blockquote>
<p>The larger the word, the more we use it.The smaller the word, the more uncommon it is.</p>
</blockquote>
<p>A very good explanation on Zips law is <a href="https://medium.com/@devalshah1619/a-mysterious-law-so-simple-and-yet-so-universal-aa9f1c8903d1#:~:text=Zipf&#39;s%20Law%20was%20proposed%20by,pattern%20that%20appears%20in%20language.&amp;text=Given%20a%20large%20corpus%20of,its%20rank%20in%20frequency%20table">here</a></p>
<p>What is astonishing is that this law holds true for almost all huge natural language corpus’s out there.For eg : Books,Religious scripts even temperature trends over past years etc. If you have made this far you might be wondering what makes this simple mathematical law based on language patterns so special.Actually significant part of research done by mankind shows that zipf’s law appear almost everywhere</p>
<div class="note">
<p>I will apply Zips Law in Hausa Language here:</p>
</div>
<p>Now, we can examine Zipf’s law for Jane Austen’s novels with just a few lines of dplyr functions.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="tf-idf.html#cb18-1"></a>freq_by_rank &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb18-2"><a href="tf-idf.html#cb18-2"></a><span class="st">  </span><span class="kw">group_by</span>(book) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb18-3"><a href="tf-idf.html#cb18-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">row_number</span>(), </span>
<span id="cb18-4"><a href="tf-idf.html#cb18-4"></a>         <span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span> =<span class="st"> </span>n<span class="op">/</span>total)</span>
<span id="cb18-5"><a href="tf-idf.html#cb18-5"></a></span>
<span id="cb18-6"><a href="tf-idf.html#cb18-6"></a>freq_by_rank</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 7
## # Groups:   book [6]
##    book              word      n  total term_fre  rank `term frequency`
##    &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;            &lt;dbl&gt;
##  1 Mansfield Park    the    6206 160460   0.0387     1           0.0387
##  2 Mansfield Park    to     5475 160460   0.0341     2           0.0341
##  3 Mansfield Park    and    5438 160460   0.0339     3           0.0339
##  4 Emma              to     5239 160996   0.0325     1           0.0325
##  5 Emma              the    5201 160996   0.0323     2           0.0323
##  6 Emma              and    4896 160996   0.0304     3           0.0304
##  7 Mansfield Park    of     4778 160460   0.0298     4           0.0298
##  8 Pride &amp; Prejudice the    4331 122204   0.0354     1           0.0354
##  9 Emma              of     4291 160996   0.0267     4           0.0267
## 10 Pride &amp; Prejudice to     4162 122204   0.0341     2           0.0341
## # … with 40,369 more rows</code></pre>
<p>The <code>rank</code> column here tells us the rank of each word within the frequency table; the table was already ordered by <code>n</code> so we could use row_number() to find the rank. Then, we can calculate the term frequency in the same way we did before.</p>
<p>Zipf’s law is often visualized by plotting <code>rank</code> on the x-axis and term <code>frequency on the y-axis</code>, on logarithmic scales. Plotting this way, an inversely proportional relationship will have a constant, negative slope.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="tf-idf.html#cb20-1"></a>freq_by_rank <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb20-2"><a href="tf-idf.html#cb20-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rank, <span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span>, <span class="dt">color =</span> book)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb20-3"><a href="tf-idf.html#cb20-3"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.1</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb20-4"><a href="tf-idf.html#cb20-4"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span></span>
<span id="cb20-5"><a href="tf-idf.html#cb20-5"></a><span class="st">  </span><span class="kw">scale_y_log10</span>()</span></code></pre></div>
<p><img src="Reseach-Book_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We see that all six of Jane Austen’s novels are similar to each other, and that the relationship between rank and frequency does have negative slope</p>
</div>
<div id="the-bind_tf_idf-function" class="section level2 unnumbered" number="">
<h2>3.3 The bind_tf_idf function</h2>
<p>The idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection or corpus of documents.</p>
<blockquote>
<p>Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common</p>
</blockquote>
<p>The <code>bind_tf_idf</code> function in the tidytext package takes</p>
<ul>
<li>a tidy text dataset as input with one row per token (term), per document.</li>
<li>One column (word here) contains the terms/tokens,</li>
<li>one column contains the documents (book in this case), and</li>
<li>the last necessary column contains the counts, how many times each document contains each term (n in this example).</li>
</ul>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="tf-idf.html#cb21-1"></a>book_words &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span></span>
<span id="cb21-2"><a href="tf-idf.html#cb21-2"></a><span class="st">  </span><span class="kw">bind_tf_idf</span>(word, book, n)</span>
<span id="cb21-3"><a href="tf-idf.html#cb21-3"></a></span>
<span id="cb21-4"><a href="tf-idf.html#cb21-4"></a>book_words</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 8
##    book              word      n  total term_fre     tf   idf tf_idf
##    &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 Mansfield Park    the    6206 160460   0.0387 0.0387     0      0
##  2 Mansfield Park    to     5475 160460   0.0341 0.0341     0      0
##  3 Mansfield Park    and    5438 160460   0.0339 0.0339     0      0
##  4 Emma              to     5239 160996   0.0325 0.0325     0      0
##  5 Emma              the    5201 160996   0.0323 0.0323     0      0
##  6 Emma              and    4896 160996   0.0304 0.0304     0      0
##  7 Mansfield Park    of     4778 160460   0.0298 0.0298     0      0
##  8 Pride &amp; Prejudice the    4331 122204   0.0354 0.0354     0      0
##  9 Emma              of     4291 160996   0.0267 0.0267     0      0
## 10 Pride &amp; Prejudice to     4162 122204   0.0341 0.0341     0      0
## # … with 40,369 more rows</code></pre>
<p>From the above table, we can see that the tf-idf are zero for these extremely common words. So the idf term (which will then be the natural log of 1) is zero.</p>
<p>The inverse document frequency (and thus tf-idf) is very low (near zero) for words that occur in many of the documents in a collection; this is how this approach decreases the weight for common words.</p>
<blockquote>
<p>The inverse document frequency will be a higher number for words that occur in fewer of the documents in the collection.</p>
</blockquote>
<p>Let’s look at terms with high tf-idf in Jane Austen’s works.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="tf-idf.html#cb23-1"></a>book_words <span class="op">%&gt;%</span></span>
<span id="cb23-2"><a href="tf-idf.html#cb23-2"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>total) <span class="op">%&gt;%</span></span>
<span id="cb23-3"><a href="tf-idf.html#cb23-3"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(tf_idf))</span></code></pre></div>
<pre><code>## # A tibble: 40,379 x 7
##    book                word          n term_fre      tf   idf  tf_idf
##    &lt;fct&gt;               &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 Sense &amp; Sensibility elinor      623  0.00519 0.00519  1.79 0.00931
##  2 Sense &amp; Sensibility marianne    492  0.00410 0.00410  1.79 0.00735
##  3 Mansfield Park      crawford    493  0.00307 0.00307  1.79 0.00551
##  4 Pride &amp; Prejudice   darcy       373  0.00305 0.00305  1.79 0.00547
##  5 Persuasion          elliot      254  0.00304 0.00304  1.79 0.00544
##  6 Emma                emma        786  0.00488 0.00488  1.10 0.00536
##  7 Northanger Abbey    tilney      196  0.00252 0.00252  1.79 0.00452
##  8 Emma                weston      389  0.00242 0.00242  1.79 0.00433
##  9 Pride &amp; Prejudice   bennet      294  0.00241 0.00241  1.79 0.00431
## 10 Persuasion          wentworth   191  0.00228 0.00228  1.79 0.00409
## # … with 40,369 more rows</code></pre>
<p>In the above, we see that all are proper nouns, names that are in fact important in these novels. None of them occur in all of novels, and they are important, characteristic words for each text within the corpus of Jane Austen’s novels.</p>
<blockquote>
<p>Note: Some of the values for idf are the same for different terms because there are 6 documents in this corpus and we are seeing the numerical value for ln(6/1),(6/2)</p>
</blockquote>
<p>Let’s look at a visualization for these high tf-idf words in Figure 3.4.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="tf-idf.html#cb25-1"></a>book_words <span class="op">%&gt;%</span></span>
<span id="cb25-2"><a href="tf-idf.html#cb25-2"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(tf_idf)) <span class="op">%&gt;%</span></span>
<span id="cb25-3"><a href="tf-idf.html#cb25-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">factor</span>(word, <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">unique</span>(word)))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb25-4"><a href="tf-idf.html#cb25-4"></a><span class="st">  </span><span class="kw">group_by</span>(book) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb25-5"><a href="tf-idf.html#cb25-5"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb25-6"><a href="tf-idf.html#cb25-6"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb25-7"><a href="tf-idf.html#cb25-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(word, tf_idf, <span class="dt">fill =</span> book)) <span class="op">+</span></span>
<span id="cb25-8"><a href="tf-idf.html#cb25-8"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb25-9"><a href="tf-idf.html#cb25-9"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="st">&quot;tf-idf&quot;</span>) <span class="op">+</span></span>
<span id="cb25-10"><a href="tf-idf.html#cb25-10"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>book, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></span>
<span id="cb25-11"><a href="tf-idf.html#cb25-11"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<pre><code>## Selecting by tf_idf</code></pre>
<p><img src="Reseach-Book_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<blockquote>
<p>What measuring tf-idf has done here is show us that Jane Austen used similar language across her six novels, and what distinguishes one novel from the rest within the collection of her works are the proper nouns, the names of people and places. This is the point of tf-idf; it identifies words that are important to one document within a collection of documents.</p>
</blockquote>
</div>
<div id="a-corpus-of-physics-texts" class="section level2 unnumbered" number="">
<h2>3.4 A corpus of physics texts</h2>
<p>Let’s work with another corpus of documents, to see what terms are important in a different set of works. We are going to use the following books</p>
<ul>
<li>Discourse on Floating Bodies by Galileo Galilei,</li>
<li>Treatise on Light by Christiaan Huygens,</li>
<li>Experiments with Alternate Currents of High Potential and High Frequency by Nikola Tesla, and</li>
<li>Relativity: The Special and General Theory by Albert Einstein.</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="tf-idf.html#cb27-1"></a><span class="kw">library</span>(gutenbergr)</span>
<span id="cb27-2"><a href="tf-idf.html#cb27-2"></a></span>
<span id="cb27-3"><a href="tf-idf.html#cb27-3"></a>physics &lt;-<span class="st"> </span><span class="kw">gutenberg_download</span>(<span class="kw">c</span>(<span class="dv">37729</span>, <span class="dv">14725</span>, <span class="dv">13476</span>, <span class="dv">30155</span>), </span>
<span id="cb27-4"><a href="tf-idf.html#cb27-4"></a>                              <span class="dt">meta_fields =</span> <span class="st">&quot;author&quot;</span>)</span></code></pre></div>
<pre><code>## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest</code></pre>
<pre><code>## Using mirror http://aleph.gutenberg.org</code></pre>
<p>Let use unnest the text</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="tf-idf.html#cb30-1"></a>physics_words &lt;-<span class="st">  </span>physics <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb30-2"><a href="tf-idf.html#cb30-2"></a><span class="st">  </span><span class="kw">unnest_tokens</span>(word , text) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb30-3"><a href="tf-idf.html#cb30-3"></a><span class="st">  </span><span class="kw">count</span>(author, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-4"><a href="tf-idf.html#cb30-4"></a>physics_words</span></code></pre></div>
<pre><code>## # A tibble: 12,671 x 3
##    author              word      n
##    &lt;chr&gt;               &lt;chr&gt; &lt;int&gt;
##  1 Galilei, Galileo    the    3760
##  2 Tesla, Nikola       the    3604
##  3 Huygens, Christiaan the    3553
##  4 Einstein, Albert    the    2993
##  5 Galilei, Galileo    of     2049
##  6 Einstein, Albert    of     2028
##  7 Tesla, Nikola       of     1737
##  8 Huygens, Christiaan of     1708
##  9 Huygens, Christiaan to     1207
## 10 Tesla, Nikola       a      1176
## # … with 12,661 more rows</code></pre>
<p>Let’s go ahead and calculate tf-idf, then visualize the high tf-idf words</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="tf-idf.html#cb32-1"></a>plot_physics &lt;-<span class="st">  </span>physics_words <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb32-2"><a href="tf-idf.html#cb32-2"></a><span class="st">   </span><span class="kw">bind_tf_idf</span>(word, author , n) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># author here is the document, word = tokens, n = number of each token</span></span>
<span id="cb32-3"><a href="tf-idf.html#cb32-3"></a><span class="st">   </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">fct_reorder</span>(word, tf_idf)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb32-4"><a href="tf-idf.html#cb32-4"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="kw">factor</span>(author, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Galilei, Galileo&quot;</span>,</span>
<span id="cb32-5"><a href="tf-idf.html#cb32-5"></a>                                            <span class="st">&quot;Huygens, Christiaan&quot;</span>, </span>
<span id="cb32-6"><a href="tf-idf.html#cb32-6"></a>                                            <span class="st">&quot;Tesla, Nikola&quot;</span>,</span>
<span id="cb32-7"><a href="tf-idf.html#cb32-7"></a>                                            <span class="st">&quot;Einstein, Albert&quot;</span>)))</span>
<span id="cb32-8"><a href="tf-idf.html#cb32-8"></a></span>
<span id="cb32-9"><a href="tf-idf.html#cb32-9"></a></span>
<span id="cb32-10"><a href="tf-idf.html#cb32-10"></a>plot_physics</span></code></pre></div>
<pre><code>## # A tibble: 12,671 x 6
##    author              word      n     tf   idf tf_idf
##    &lt;fct&gt;               &lt;fct&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 Galilei, Galileo    the    3760 0.0935     0      0
##  2 Tesla, Nikola       the    3604 0.0913     0      0
##  3 Huygens, Christiaan the    3553 0.0928     0      0
##  4 Einstein, Albert    the    2993 0.0952     0      0
##  5 Galilei, Galileo    of     2049 0.0510     0      0
##  6 Einstein, Albert    of     2028 0.0645     0      0
##  7 Tesla, Nikola       of     1737 0.0440     0      0
##  8 Huygens, Christiaan of     1708 0.0446     0      0
##  9 Huygens, Christiaan to     1207 0.0315     0      0
## 10 Tesla, Nikola       a      1176 0.0298     0      0
## # … with 12,661 more rows</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="tf-idf.html#cb34-1"></a>plot_physics <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb34-2"><a href="tf-idf.html#cb34-2"></a><span class="st">  </span><span class="kw">group_by</span>(author) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb34-3"><a href="tf-idf.html#cb34-3"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>, tf_idf) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb34-4"><a href="tf-idf.html#cb34-4"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb34-5"><a href="tf-idf.html#cb34-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">reorder</span>(word, tf_idf)) <span class="op">%&gt;%</span></span>
<span id="cb34-6"><a href="tf-idf.html#cb34-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(word, tf_idf, <span class="dt">fill =</span> author)) <span class="op">+</span></span>
<span id="cb34-7"><a href="tf-idf.html#cb34-7"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb34-8"><a href="tf-idf.html#cb34-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="st">&quot;tf-idf&quot;</span>) <span class="op">+</span></span>
<span id="cb34-9"><a href="tf-idf.html#cb34-9"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>author, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></span>
<span id="cb34-10"><a href="tf-idf.html#cb34-10"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="Reseach-Book_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Lets explore some strange word from the graph above. One thing we see here is “k” in the Einstein text?! Let us us the raw text and select what “K” means:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="tf-idf.html#cb35-1"></a>physics <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb35-2"><a href="tf-idf.html#cb35-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(text, <span class="st">&quot;_k_&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb35-3"><a href="tf-idf.html#cb35-3"></a><span class="st">  </span><span class="kw">select</span>(text)</span></code></pre></div>
<pre><code>## # A tibble: 7 x 1
##   text                                                                  
##   &lt;chr&gt;                                                                 
## 1 surface AB at the points AK_k_B. Then instead of the hemispherical    
## 2 would needs be that from all the other points K_k_B there should      
## 3 necessarily be equal to CD, because C_k_ is equal to CK, and C_g_ to  
## 4 the crystal at K_k_, all the points of the wave CO_oc_ will have      
## 5 O_o_ has reached K_k_. Which is easy to comprehend, since, of these   
## 6 CO_oc_ in the crystal, when O_o_ has arrived at K_k_, because it forms
## 7 ρ is the average density of the matter and _k_ is a constant connected</code></pre>
<p>Some cleaning up of the text may be in order. Also notice that there are separate “co” and “ordinate” items in the high tf-idf words for the Einstein text; the unnest_tokens() function separates around punctuation like hyphens by default. Notice that the tf-idf scores for “co” and “ordinate” are close to same!</p>
<p>Again,“AB”, “RC”, and so forth are names of rays, circles, angles, and so forth for Huygens.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="tf-idf.html#cb37-1"></a>physics <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb37-2"><a href="tf-idf.html#cb37-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(text, <span class="st">&quot;RC&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb37-3"><a href="tf-idf.html#cb37-3"></a><span class="st">  </span><span class="kw">select</span>(text)</span></code></pre></div>
<pre><code>## # A tibble: 44 x 1
##    text                                                                  
##    &lt;chr&gt;                                                                 
##  1 line RC, parallel and equal to AB, to be a portion of a wave of light,
##  2 represents the partial wave coming from the point A, after the wave RC
##  3 be the propagation of the wave RC which fell on AB, and would be the  
##  4 transparent body; seeing that the wave RC, having come to the aperture
##  5 incident rays. Let there be such a ray RC falling upon the surface    
##  6 CK. Make CO perpendicular to RC, and across the angle KCO adjust OK,  
##  7 the required refraction of the ray RC. The demonstration of this is,  
##  8 explaining ordinary refraction. For the refraction of the ray RC is   
##  9 29. Now as we have found CI the refraction of the ray RC, similarly   
## 10 the ray _r_C is inclined equally with RC, the line C_d_ will          
## # … with 34 more rows</code></pre>
<p>Let’s remove some of these less meaningful words to make a better, more meaningful plot. Notice that we make a custom list of stop words and use anti_join() to remove them; this is a flexible approach that can be used in many situations. We will need to go back a few steps since we are removing words from the tidy data frame.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="tf-idf.html#cb39-1"></a>mystopwords &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">word =</span> <span class="kw">c</span>(<span class="st">&quot;eq&quot;</span>, <span class="st">&quot;co&quot;</span>, <span class="st">&quot;rc&quot;</span>, <span class="st">&quot;ac&quot;</span>, <span class="st">&quot;ak&quot;</span>, <span class="st">&quot;bn&quot;</span>, </span>
<span id="cb39-2"><a href="tf-idf.html#cb39-2"></a>                                   <span class="st">&quot;fig&quot;</span>, <span class="st">&quot;file&quot;</span>, <span class="st">&quot;cg&quot;</span>, <span class="st">&quot;cb&quot;</span>, <span class="st">&quot;cm&quot;</span>,</span>
<span id="cb39-3"><a href="tf-idf.html#cb39-3"></a>                               <span class="st">&quot;ab&quot;</span>, <span class="st">&quot;_k&quot;</span>, <span class="st">&quot;_k_&quot;</span>, <span class="st">&quot;_x&quot;</span>))</span>
<span id="cb39-4"><a href="tf-idf.html#cb39-4"></a></span>
<span id="cb39-5"><a href="tf-idf.html#cb39-5"></a>physics_words &lt;-<span class="st"> </span><span class="kw">anti_join</span>(physics_words, mystopwords, </span>
<span id="cb39-6"><a href="tf-idf.html#cb39-6"></a>                           <span class="dt">by =</span> <span class="st">&quot;word&quot;</span>)</span>
<span id="cb39-7"><a href="tf-idf.html#cb39-7"></a></span>
<span id="cb39-8"><a href="tf-idf.html#cb39-8"></a>plot_physics &lt;-<span class="st"> </span>physics_words <span class="op">%&gt;%</span></span>
<span id="cb39-9"><a href="tf-idf.html#cb39-9"></a><span class="st">  </span><span class="kw">bind_tf_idf</span>(word, author, n) <span class="op">%&gt;%</span></span>
<span id="cb39-10"><a href="tf-idf.html#cb39-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">str_remove_all</span>(word, <span class="st">&quot;_&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb39-11"><a href="tf-idf.html#cb39-11"></a><span class="st">  </span><span class="kw">group_by</span>(author) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb39-12"><a href="tf-idf.html#cb39-12"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>, tf_idf) <span class="op">%&gt;%</span></span>
<span id="cb39-13"><a href="tf-idf.html#cb39-13"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb39-14"><a href="tf-idf.html#cb39-14"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">reorder_within</span>(word, tf_idf, author)) <span class="op">%&gt;%</span></span>
<span id="cb39-15"><a href="tf-idf.html#cb39-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="kw">factor</span>(author, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Galilei, Galileo&quot;</span>,</span>
<span id="cb39-16"><a href="tf-idf.html#cb39-16"></a>                                            <span class="st">&quot;Huygens, Christiaan&quot;</span>,</span>
<span id="cb39-17"><a href="tf-idf.html#cb39-17"></a>                                            <span class="st">&quot;Tesla, Nikola&quot;</span>,</span>
<span id="cb39-18"><a href="tf-idf.html#cb39-18"></a>                                            <span class="st">&quot;Einstein, Albert&quot;</span>)))</span>
<span id="cb39-19"><a href="tf-idf.html#cb39-19"></a></span>
<span id="cb39-20"><a href="tf-idf.html#cb39-20"></a><span class="kw">ggplot</span>(plot_physics, <span class="kw">aes</span>(word, tf_idf, <span class="dt">fill =</span> author)) <span class="op">+</span></span>
<span id="cb39-21"><a href="tf-idf.html#cb39-21"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb39-22"><a href="tf-idf.html#cb39-22"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="st">&quot;tf-idf&quot;</span>) <span class="op">+</span></span>
<span id="cb39-23"><a href="tf-idf.html#cb39-23"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>author, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></span>
<span id="cb39-24"><a href="tf-idf.html#cb39-24"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb39-25"><a href="tf-idf.html#cb39-25"></a><span class="st">  </span><span class="kw">scale_x_reordered</span>()</span></code></pre></div>
<p><img src="Reseach-Book_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="SA.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Reseach Book.pdf", "Reseach Book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
